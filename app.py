# app.py
import os
import streamlit as st
from modules import embed_store, generator

# ==========================
# INIT
# ==========================
st.set_page_config(page_title="RAG Chatbot", page_icon="ü§ñ")
st.title("üìÑ RAG Chatbot powered by Groq + ChromaDB")

# Kh·ªüi t·∫°o l·ªõp l∆∞u tr·ªØ embedding
store = embed_store.EmbedStore(collection_name="rag_collection")

# ==========================
# SIDEBAR: UPLOAD FILE
# ==========================
st.sidebar.header("üìÇ Upload t√†i li·ªáu")
uploaded_files = st.sidebar.file_uploader(
    "Ch·ªçn file PDF, DOCX, ho·∫∑c TXT",
    type=["pdf", "docx", "txt"],
    accept_multiple_files=True
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        temp_path = os.path.join("uploads", uploaded_file.name)
        os.makedirs("uploads", exist_ok=True)
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # Th√™m v√†o vector DB (chung collection)
        try:
            store.add_document(temp_path)
            st.sidebar.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {uploaded_file.name}")
        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_file.name}: {e}")

# ==========================
# MAIN CHAT INTERFACE
# ==========================
st.subheader("üí¨ Chat v·ªõi t√†i li·ªáu c·ªßa b·∫°n")

# Kh·ªüi t·∫°o session l∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# Input c√¢u h·ªèi
user_query = st.text_input("Nh·∫≠p c√¢u h·ªèi:")

if st.button("H·ªèi") and user_query.strip():
    # ==========================
    # RETRIEVAL CONTEXT
    # ==========================
    context_text = ""
    try:
        context_docs = store.similarity_search(user_query, k=5)
        if context_docs:
            context_text = "\n\n".join([doc['text'] for doc in context_docs])
    except Exception as e:
        st.warning(f"L·ªói truy xu·∫•t context: {e}")

    # ==========================
    # GENERATE ANSWER (kh√¥ng streaming)
    # ==========================
    try:
        # Gom to√†n b·ªô output t·ª´ generate_answer_stream
        answer_chunks = generator.generate_answer_stream(user_query, context_text)
        answer_text = "".join([chunk for chunk in answer_chunks])

        st.session_state["chat_history"].append(("üßë", user_query))
        st.session_state["chat_history"].append(("ü§ñ", answer_text))
    except Exception as e:
        st.warning(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {e}")

# ==========================
# DISPLAY CHAT HISTORY
# ==========================
for speaker, msg in st.session_state["chat_history"]:
    st.markdown(f"**{speaker}:** {msg}")


