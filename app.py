import os
import streamlit as st
from modules import embed_store, generator

# ==========================
# INIT
# ==========================
st.set_page_config(page_title="RAG Chatbot", page_icon="ü§ñ")
st.title("üìÑ RAG Chatbot powered by Groq + ChromaDB")

# Kh·ªüi t·∫°o l·ªõp l∆∞u tr·ªØ embedding
store = embed_store.EmbedStore(collection_name="rag_collection")

# ==========================
# SIDEBAR: UPLOAD FILE
# ==========================
st.sidebar.header("üìÇ Upload t√†i li·ªáu")
uploaded_files = st.sidebar.file_uploader(
    "Ch·ªçn file PDF, DOCX, ho·∫∑c TXT",
    type=["pdf", "docx", "txt"],
    accept_multiple_files=True
)

# T·∫°o th∆∞ m·ª•c uploads n·∫øu ch∆∞a c√≥
os.makedirs("uploads", exist_ok=True)

# X·ª≠ l√Ω upload
if uploaded_files:
    for uploaded_file in uploaded_files:
        temp_path = os.path.join("uploads", uploaded_file.name)
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        # Th√™m v√†o vector DB (chung collection)
        try:
            store.add_document(temp_path)
            st.sidebar.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {uploaded_file.name}")
        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_file.name}: {e}")

# ==========================
# HI·ªÇN TH·ªä FILE TRONG TH∆Ø M·ª§C UPLOAD
# ==========================
st.sidebar.header("üìÇ Danh s√°ch t√†i li·ªáu ƒë√£ upload")
upload_files_list = os.listdir("uploads")
if upload_files_list:
    for f in upload_files_list:
        st.sidebar.markdown(f"- {f}")
else:
    st.sidebar.info("Ch∆∞a c√≥ file n√†o ƒë∆∞·ª£c upload.")

# ==========================
# MAIN CHAT INTERFACE
# ==========================
st.subheader("üí¨ Chat v·ªõi t√†i li·ªáu c·ªßa b·∫°n")

# Kh·ªüi t·∫°o session l∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# Hi·ªÉn th·ªã chat history tr∆∞·ªõc (ƒë·ªÉ thanh nh·∫≠p lu√¥n n·∫±m d∆∞·ªõi trang)
for speaker, msg in st.session_state["chat_history"]:
    st.markdown(f"**{speaker}:** {msg}")

# Thanh h·ªèi ƒë√°p ·ªü ƒê√ÅY trang (pinned) ‚Äî kh√¥ng thay ƒë·ªïi logic x·ª≠ l√Ω
user_query = st.chat_input("Nh·∫≠p c√¢u h·ªèi...")

if user_query and user_query.strip():
    # L·∫•y context
    context_text = ""
    try:
        context_docs = store.similarity_search(user_query, k=5)
        if context_docs:
            context_text = "\n\n".join([doc['text'] for doc in context_docs])
    except Exception as e:
        st.warning(f"L·ªói truy xu·∫•t context: {e}")

    # Sinh c√¢u tr·∫£ l·ªùi
    try:
        answer_text = "".join(generator.generate_answer_stream(user_query, context_text))
        # L∆∞u l·ªãch s·ª≠ chat
        st.session_state["chat_history"].append(("üßë", user_query))
        st.session_state["chat_history"].append(("ü§ñ", answer_text))
        # Hi·ªÉn th·ªã ngay tin nh·∫Øn v·ª´a g·ª≠i/tr·∫£ l·ªùi (t√πy ch·ªçn)
        st.markdown(f"**üßë:** {user_query}")
        st.markdown(f"**ü§ñ:** {answer_text}")
    except Exception as e:
        st.error(f"‚ö†Ô∏è L·ªói khi g·ªçi LLM: {e}")
